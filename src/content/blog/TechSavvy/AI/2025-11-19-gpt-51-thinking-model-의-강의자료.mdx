---
title: "GPT 5.1 Thinking Model 의 강의자료"
author: "Jay Lee"
pubDate: "2025-11-19T10:33:00.000Z"
lastEditedTime: "2025-11-19T10:33:00.000Z"
categories: ["TechSavvy", "AI"]
tags: ["AI","LLM","Technology"]
---


## 1. 전체 강의 흐름 (디테일 버전)


### 0. 오프닝 (5분)


**목표**

- “AI 기술 설명회”가 아니라,

    **“AI 시대에 사람은 어떤 방식으로 일하고 생각해야 하는가”** 라는 철학·실무 이야기라는 걸 못 박기.


**구성**

- 한 줄 문제제기:
    > “이제는 ‘내가 직접 문제를 푸는 사람’이 아니라,
>
>     **‘문제가 잘 풀리게 환경을 설계하는 사람’** 이 더 중요한 시대가 오고 있습니다.”
>
>
- 오늘의 세 가지 키워드 소개
    1. **환경(Environment)**
    2. **루브릭(Rubric: 평가 기준표)**
    3. **오케스트레이션(Orchestration: 일을 조합해서 굴리는 능력)**

---


### 1. 지금 프론티어 모델은 어떻게 배우고 있나 (20분)


### 1-1. “AI도 혼자 문제 안 푼다 – 환경 속에서 푼다”

- AlphaGo / AlphaZero / OpenAI Five 이야기
    - 바둑, 체스, 스타크래프트, Dota2 같은 게임에서

        **“좋은 환경 + 무한 반복 + 보상 설계”** 로 인간을 넘어섬. [arXiv+1](https://arxiv.org/pdf/2509.03682?utm_source=chatgpt.com)

- 핵심 메시지:
    > “초지능도, 결국 연습장(환경) + 점수 체계(보상/루브릭) 위에서 자란다.”

### 1-2. RLHF / 인간 피드백으로 배우는 AI

- 2017년 Christiano 외 “Deep Reinforcement Learning from Human Preferences” 간단 소개 [arXiv+1](https://arxiv.org/abs/1706.03741?utm_source=chatgpt.com)
    - 사람에게 “이 답 vs 저 답, 뭐가 더 낫냐” 물어보고
    - 그 **선호(preference)** 를 학습해서 보상 모델을 만듦
    - 이후엔 사람 대신 **보상 모델이 AI를 ‘채점’** 함
- 여기서 정리:
    > “사람이 일일이 가르치는 시대 →
>
>     **사람이 ‘채점 기준(루브릭)’만 세우고,
>     평가는 보상 모델이 대신하는 시대** 로 넘어가고 있다.” [IBM+1](https://www.ibm.com/think/topics/rlhf?utm_source=chatgpt.com)
>
>

### 1-3. Kimi K2 / 자가 학습 + 자기 비평 루브릭

- Kimi K2 요약 (일반인 버전) [arXiv+1](https://arxiv.org/html/2507.20534v1?utm_source=chatgpt.com)
    - 1조 파라미터급 MoE 모델
    - **Self-critique Rubric Reward**
        - 스스로 여러 답안을 만든 뒤
        - **자기 내부 “핵심 가치 루브릭(명확성, 도움됨, 객관성 등)”** 으로 서로 비교·채점
        - 그걸 보상으로 써서 자기 개선
- 메시지:
    > “요즘 최전선 AI는
>     1. **환경(연습장)** 을 갖고
>     2. **루브릭(핵심 가치 기준표)** 를 쓰고
>     3. 그 안에서 **무한 루프를 돌며 자기 개선** 을 한다.”
>

---


### 2. 이게 우리 삶/업무랑 무슨 상관이냐 (15분)


### 2-1. “문제 해결자”에서 “환경 설계자”로의 전환

- 옛날 모드:
    - “엑셀 수식 내가 다 짠다”, “자료를 내가 다 뒤진다”
- 앞으로 모드:
    - “엑셀, AI, 동료, 프로세스를 **어떻게 조합하면** 일이 알아서 굴러가게 만들 수 있을까?”
- 한 줄 정리:
    > “내가 일하는 게 아니라, 일이 굴러가게 만드는 환경을 설계한다.”

### 2-2. 생활 예시 2–3개

- 예시 1: **다이어트 / 운동 루틴**
    - 매번 “오늘은 뭐 하지?” 고민 vs
    - 미리: 식단·운동 루브릭 + 일정 + 자동 알림 + 친구 피드백 환경
- 예시 2: **업무 보고**
    - 매번 새 PPT 고생 vs
    - “좋은 보고의 루브릭(간결, 핵심, 숫자, 시각화)을 만들고

        템플릿 + AI 요약 + 정기 리뷰” 환경 구축


---


### 3. 루브릭이란 무엇인가 – 사람 기준에서부터 (20분)


### 3-1. 루브릭, 사실 우리 일상에도 늘 있었다

- 시험 채점표, 운전면허 시험, 면접 평가표
- 공통점:
    - **항목**: 예) 정확성, 안전성, 협업, 태도
    - 각 항목별 **점수 스케일**: 1~5점
    - **가중치**: 어떤 항목은 더 중요

### 3-2. LLM 평가 루브릭 예시 (인간 눈에 보이게 설명)


최근 논문/블로그에서 사용하는 대표 기준들:[ACM Digital Library+1](https://dl.acm.org/doi/10.1145/3641289?utm_source=chatgpt.com)

- **Helpfulness**: 사용자가 진짜로 도움을 받았는가
- **Honesty**: 모르면 “모른다”고 말하는가 (지어내지 않는가)
- **Harmlessness**: 위험하거나 공격적인 답은 피했는가
- **Relevance**: 질문과 관련된 내용만 말하는가
- **Factual Accuracy**: 사실관계가 맞는가
- **Clarity**: 일반인이 이해하기 쉬운가
- **Depth**: 피상적 설명이 아니라 핵심까지 들어갔는가
- **Structure**: 논리적 흐름과 구성은 깔끔한가
- **Reasoning Quality**: 생각의 과정이 논리적인가
- **Style Alignment**: 요청한 톤/스타일을 잘 맞추는가

→ 여기서 관찰 포인트:

> “좋은 답변이란,
>
> **단일 점수가 아니라 이런 항목들의 벡터** 다.”
>
>

---


### 4. 평가 환경과 오케스트레이션 (20분)


### 4-1. “환경”을 구성하는 4요소

1. **Input**
    - 문제 / 데이터 / 프롬프트
2. **Agent**
    - 사람, AI, 또는 둘이 섞인 팀
3. **Tool**
    - 검색, 스프레드시트, 코드 실행, 브라우저, 내부 시스템 등
4. **Feedback & Rubric**
    - 누가, 어떤 기준으로, 얼마나 자주 평가해 주는가

이 넷이 모여 하나의 “RL-Gym 같은 일터 환경”이 됨.


### 4-2. 인간과 AI의 역할 분담

- 인간이 잘하는 것:
    - **가치 설정**: 무엇이 좋은 답/나쁜 답인가?
    - **루브릭 설계**: 기준 항목과 가중치 설정
    - **엣지 케이스 판단**: 애매한 상황에서 최종 결정
- AI가 잘하는 것:
    - 루브릭에 맞춰 **대량 평가**
    - **자기 비평(Self-critique)** + 후보 여러 개 만들어 비교 [ACL Anthology+1](https://aclanthology.org/2025.acl-long.675.pdf?utm_source=chatgpt.com)

---


### 5. 실습/스토리: “재미 있는 웹게임을 가지고 루브릭·에이전트·환경 만들기” (25분)


여기는 강의에서 **라이브 시나리오**로만 가도 되고,


준비 여건 되면 실제 간단한 웹 페이지 데모로 만들어도 좋음.


### 5-1. 시나리오 설정

- 가상의 웹게임: **“스토리 이어 말하기 게임”**
    - 사용자에게 프롬프트:
        > “오늘 있었던 일을 3줄로 요약해 주세요.”
    - AI가 그걸 읽고
        - 한 줄로 요약해 준다
        - 이모지 2개를 붙여준다
- 여기서 우리가 하고 싶은 일:
    - “AI가 만들어 주는 요약이 **좋은지 나쁜지** 평가하고,

        더 좋게 만들도록 **환경 + 루브릭 + 오케스트레이션** 을 설계해 보기”


### 5-2. 루브릭 설계 예시


예를 들어 이런 5항목:

1. **정확성** – 원래 내용과 의미가 잘 유지되는가
2. **간결성** – 너무 장황하지 않고 한 눈에 들어오는가
3. **감정 톤** – 사용자의 감정 상태를 잘 살렸는가
4. **명확성** – 어려운 표현 없이 누구나 이해 가능한가
5. **재미 요소** – 이모지 선택이 어색하지 않고 공감 가는가

각 항목을 1~5점으로 두고, 중요도에 따라 가중치 설정.


### 5-3. 오케스트레이션 구조 (Cursor / Claude Code를 예로)

- **Agent 1 – Writer**
    - 사용자의 일기를 요약하는 AI
- **Agent 2 – Judge**
    - 위 루브릭으로 Writer의 결과를 채점하는 AI (LLM-as-a-judge) [ACL Anthology+1](https://aclanthology.org/2025.acl-long.675.pdf?utm_source=chatgpt.com)
- **Agent 3 – Coach**
    - 점수가 낮을 때, 어떤 점을 고치면 좋을지 피드백을 주는 AI
- **Human**
    - 루브릭을 설계하고, 가끔 샘플을 직접 보며 “Judge가 잘 평가하는지” 감시

이걸 **“한 번 돌리고 끝”이 아니라,**

- 매주 루브릭을 조금씩 수정
- 낮은 점수 케이스를 모아서 회고

    하는 **루프 구조**까지 보여주는 게 포인트.


---


### 6. 철학적 정리: “해결자가 아니라 환경 설계자로 산다는 것” (10–15분)


### 6-1. 앞으로 우리에게 필요한 4가지 태도

1. **질문력**
    - “뭘 시킬까?”가 아니라
    - “**어떤 환경이 만들어지면 일이 저절로 풀릴까?**”
2. **조합력(Orchestration)**
    - 사람 + AI + 툴 + 프로세스를 **악기처럼 섞어 쓰는 능력**
3. **관찰–리팩터링 루프**
    - 한번 만든 환경을 **관찰 → 튜닝 → 재설계** 하는 습관
4. **가치·안전 감각**
    - RLHF / 3H(Helpful, Honest, Harmless)가 하는 질문을

        우리 삶에도 던져보기:

        > “이 결정은 나와 주변에 정말 도움이 되는가, 정직한가, 해를 덜 주는가?” ACM Digital Library+1

### 6-2. 마무리 멘트

- “AI는 이미 **자기 환경을 만들고, 자기 루브릭으로 자기 자신을 평가하며** 성장하고 있습니다.

    인간에게 남은 역할은, 그 위에 올라서서


    **무엇을 위해, 어떤 방향으로 환경을 설계할지 결정하는 것** 입니다.”

