---
title: "DH Lee chatbot 만들기의 여정-1"
author: "Jay Lee"
pubDate: "2023-11-29 00:00:00"
categories: ["TechSavvy", "AI", "C++"]
tags: ["TechSavvy", "AI", "Python", "C++"]
---


# 다시시작하는 CPS 2기

CPS(Crash Python course for SANS family)라는 Python강의를 2023년 초부터 3개월 정도를 진행했었다.
파이썬은 쉽고 재밌게 배울수 있으며 청중들이 이걸로 할수 있는게 엄청 많아요~ 하고 가스라이팅 하고있는데,
ChatGPT가 갑자기 혜성처럼 나타나서 강의하는 도중에 강사인 나도 이게 파이썬 강의인지 ChatGPT잘쓰기 강의인지 알수가 없을정도로 산만하게 3개월의 강의를 마무리 했더랬다.

강의를 만들게 나를 조종도하셨고 열성으로 들어주신 우리 노수림교수님께 역으로 또 가스라이팅해주셔서 2024년 초에 또 2기를 시작할까하는데,
이참에 아예 LLM(Large Language Model) Pre-trained Model 중 GPT3.5, Lamma를 이용해 뭔가를 해보자라는것이 내년 강의의 골자가 될것이다.

그리고 게을로 못하던 블로깅도 매일 하자라고 마음먹었다.
어디한번 해보자구..

존경하는 DH Lee의 수많은 강의영상, 보이스, 채팅 기록을 Voice to Text등 Framework을 통해 데이터 변환하고, 레이블링 및 전처리하여,
Pretrained Model에 학습시켜 DH Lee AI Model API Service를 만들어내는것이 가장 먼저 할일이다.

이 API 텔레그램이나 Slack, 카톡등에 Chatbot으로 먼저 이용해보고, 나중에 Midjourney나 다른 상용 비쥬얼 AI서비스들과 콜라보하여 만들어볼까하는 욕심도있다.

뭐 일단 강사인 내가 빠르게 모든 스텝을 Work through 해보는게 목표이고, 이 과정을 블로그로 남길예정이다.

그리고 매일 이러한 과정을 ChatGPT4의 음성채팅서비스를 통해 논의해가며 디테일화 하는 과정을 하고있는데, 최근 기능들이 좋아져서 문서까지 아주 만들어주니 이걸 블로그에 올리지 아니할 수 있는가..

이상 마무리하고.. 

아래는 ChatGPT4 흑인아지매랑 논의한 내용을 기록한다.

# Guide to Transcribing DH Lee's Voice Data and Training with GPT-3.5

## Transcribing Voice to Text Using Microsoft Azure

### Setting Up Microsoft Azure Speech Service
1. **Create an Azure Account** and enable billing.
2. **Create a Speech Service Resource** in Azure Portal and obtain your API key and endpoint URL.
3. **Install Azure SDK** for Python using `pip install azure-cognitiveservices-speech`.

### Python Script for Transcription
```python
import azure.cognitiveservices.speech as speechsdk

def transcribe_audio(file_path, service_region, subscription_key):
    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=service_region)
    audio_input = speechsdk.AudioConfig(filename=file_path)

    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)

    result = speech_recognizer.recognize_once_async().get()
    return result.text

subscription_key = "YourAzureSubscriptionKey"
service_region = "YourServiceRegion"
audio_file_path = "path/to/your/audiofile.wav"

transcription = transcribe_audio(audio_file_path, service_region, subscription_key)
print(transcription)
```
- Replace `"YourAzureSubscriptionKey"`, `"YourServiceRegion"`, and `"path/to/your/audiofile.wav"` with your details.

### Post-Transcription Steps
- Review and correct the transcriptions.
- Store the transcriptions in a structured format.

## Training Transcribed Data with GPT-3.5

### Data Preparation for GPT-3.5
- Organize and clean the transcribed data.
- Format the data as per OpenAI's guidelines for fine-tuning.

### Fine-Tuning Process
- Access the GPT-3.5 API through OpenAI, which may offer fine-tuning capabilities.
- Upload your prepared dataset to OpenAI and fine-tune the model on this data.
- Define training parameters as needed.

### Integration and Testing
- Integrate the fine-tuned GPT-3.5 model into your application via API.
- Test the model's performance to ensure it aligns with DH Lee's style and content.

### Considerations
- Ensure you have adequate computational resources and expertise.
- Obtain DH Lee's consent and consider ethical aspects of using his data.
- Be mindful of the costs associated with API usage and training.

---

**Note:** This document is a summarized guide based on the conversation and should be adapted for specific project needs.
