---
title: "1장. LLM에서 Agentic AI로: “말 잘하는 애”를 넘어, “일을 끝내는 애”로"
author: "Jay Lee"
pubDate: "2025-12-10T05:54:00.000Z"
lastEditedTime: "2025-12-10T05:54:00.000Z"
categories: ["TechSavvy", "AI"]
tags: ["AI","LLM","Technology"]
---

# 1장. LLM에서 Agentic AI로: “말 잘하는 애”를 넘어, “일을 끝내는 애”로


챗GPT, Claude 같은 LLM이 처음 나왔을 때 사람들은 주로 이렇게 썼습니다.


질문 던지고, 답변 받고, 코드 한두 함수 뽑아 쓰고, 글 뼈대 잡게 하고.


그런데 실제로 일하는 현장에 이 모델들을 꽤 오래 붙여본 사람일수록 비슷한 느낌을 받게 됩니다.

> “생각은 잘하는데, 끝까지 일을 해주지는 않는다.”

답을 설명하는 것과,


“그 답을 바탕으로 실제로 일을 끝내는 것” 사이에는 꽤 큰 간극이 있습니다.


예를 들어 개발 환경을 떠올려 보면:


- 로그를 요약해 주고, 버그 원인을 추측해 주는 것까지는 잘합니다.

- 하지만 실제로:
    - 관련 코드를 찾아가고,
    - 수정하고,
    - 테스트를 돌리고,
    - CI 상태를 확인하고,
    - 이슈 트래커에 정리하는 것까지

        자동으로 끝내주는 경우는 거의 없습니다.


이 간극 때문에 생기는 패턴이 있습니다.


“모델이 아이디어를 주고, 사람은 그걸 들고 각종 툴과 시스템 사이를 뛰어다니며 마무리한다.”


뇌와 입은 모델이 맡고, 손발은 여전히 사람이 다 쓰는 구조죠.


Agentic AI라는 흐름은 이 간극에서 출발합니다.


단순히 “더 똑똑한 LLM”이 아니라, 아예 기본 목표를 다르게 잡습니다.

> 질문에 잘 답하는 도우미가 아니라,
>
> 목표를 받고 스스로 일을 끝까지 밀어붙이는 실행자.
>
>

그래서 여기서 중요한 건 “얼마나 말을 잘하느냐”가 아니라,


“얼마나 일을 자율적으로 끝까지 가져가느냐”입니다.


---


## AI Agent와 Agentic AI, 같은 말 같지만 다른 초점


Agent라는 말은 꽤 오래 쓰였기 때문에,


AI Agent와 Agentic AI가 뒤섞여서 쓰이는 경우가 많습니다.


하지만 요즘 논의에서 보통 이렇게 구분하는 편이 이해하기 편합니다.


- AI Agent
    - 특정 입력에 대해 미리 짜둔 정책이나 규칙으로 반응하는 모든 시스템을 넓게 포함하는 말입니다.
    - 챗봇, 간단한 자동화 스크립트, 추천 시스템까지 다 들어갈 수 있습니다.

- Agentic AI
    - LLM처럼 범용적인 추론 능력을 가진 모델을 기반으로 합니다.
    - 목표를 받으면,
        - 해야 할 일을 스스로 쪼개고,
        - 순서를 계획하고,
        - 외부 도구와 시스템을 호출하며,
        - 중간 결과를 보면서 전략을 수정하고,
        - 최종적으로 “완료된 결과물”을 만들어내려는 방향으로 설계된 시스템을 가리킵니다.

여기서 핵심은 자율성입니다.


프롬프트 한 번 → 답변 한 번의 왕복이 아니라,


“목표 달성까지 여러 번 왕복하면서 알아서 버티는 능력”에 가까운 개념입니다.


조금 더 현실적인 관점에서 보면, Agentic AI는 이런 질문들에 직접 답을 내리는 시도입니다.


- 이 시스템은 단순히 답변만 주는가, 아니면 실제 시스템 상태를 바꾸는가?

    (예: 코드 커밋, 이슈 생성, 배포, 알림 발송, DB 업데이트 등)


- 이 시스템은 매 요청을 항상 새로 시작하는가, 아니면 프로젝트·사용자·조직의 맥락을 기억하고 발전시키는가?

- 한 에이전트가 다 하려 드는 구조인가, 아니면 역할이 다른 여러 에이전트를 조율하는 구조인가?

결국 Agentic AI라는 말은


“에이전트처럼 생긴 인터페이스”를 말하는 게 아니라,


“목표를 끝까지 밀어붙이는 방식”을 말하는 쪽에 가깝습니다.


---


## 이 글이 보려는 관점: 기술 스택이 아니라 “풀스택 작동 방식”


Agentic AI 이야기를 들여다보면,


한쪽 극단은 모델 성능 이야기에만 빠지고,


다른 극단은 마케팅 용어 나열에만 시간을 쓰는 경우가 많습니다.


여기서 다루려는 관점은 조금 다릅니다.


어떤 한 기술만 확대해서 보지 않고, 실제로 의미 있게 작동하는 “풀스택 구조”를 한 번에 묶어서 보려는 관점입니다.


이때 자연스럽게 등장하는 키워드가 몇 가지 있습니다.


- MCP(Model Context Protocol)
    - LLM이 외부 시스템과 정돈된 방식으로 통신하기 위한 프로토콜입니다.
    - 일종의 “에이전트 시대의 표준 인터페이스 후보”라고 볼 수 있습니다.

- Bun
    - JS/TS 기반 에이전트와 웹·서버 애플리케이션을 빠르게 돌리기 위한 런타임·툴체인입니다.
    - Agentic 워크로드를 실제로 받쳐주는 실행 인프라에 가깝습니다.

- Claude Code
    - 개발자가 매일 쓰는 IDE 경험 속에 들어와 있는 에이전틱 환경의 대표 사례입니다.
    - 단순 코드 자동완성을 넘어서, 리포지토리 단위로 일을 받아 처리하는 쪽으로 움직이고 있습니다.

- 그리고 “사람들이 실제로 에이전트를 어떻게 쓰고 있는지”에 대한 관찰
    - 어떤 업무부터 에이전트에게 넘기는지,
    - 어디에서 불편함과 불안을 느끼는지,
    - 조직 구조와 역할이 어떻게 변하는지.

이 글의 목표는 이 요소들을 각각 분리해서 설명하는 데서 끝내지 않습니다.


대신 이런 질문에 답을 내리려 합니다.


- 이 스택이 실제로 사람의 일을 어떻게 바꾸는가?

- 어떤 패턴에서 처음으로 “Agentic AI가 없으면 안 되는 상태”가 생기는가?

- 이걸 도입하는 조직 입장에서, 기술·운영·거버넌스는 어떻게 재구성해야 하는가?

그래서 뒤의 장들은 대략 이런 흐름으로 이어집니다.


- 2장에서는 Agentic AI 전체 스택의 지도를 한 번에 그려보고,

- 3장에서는 MCP와 Agentic AI Foundation을 통해 “표준·프로토콜·생태계”를,

- 4장에서는 Bun을 통해 “AI 네이티브 런타임”이라는 개념을,

- 5장에서는 Claude Code를 통해 실제 Dev 환경에서 돌아가는 Agentic 사례를,

- 6장에서는 사람들이/조직이 에이전트를 어떻게 쓰고 있는지 패턴을,

- 7장에서는 AgentOps와 거버넌스, 그리고 앞으로의 과제를 정리합니다.

1장은 그 전체 여정의 프롤로그입니다.


“왜 이제 LLM을 넘어 Agentic AI를 이야기해야 하는가?”를 정리하고,


이후에 나올 기술·사례·운영 이야기를 받아들이기 위한 좌표를 맞추는 단계라고 보면 됩니다.
