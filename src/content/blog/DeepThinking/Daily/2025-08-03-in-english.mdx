---
title: "In English "
author: "Jay Lee"
pubDate: "2025-08-03T13:16:00.000Z"
lastEditedTime: "2025-08-03T13:22:00.000Z"
categories: ["DeepThinking", "Daily"]
tags: ["Daily","Thoughts"]
---

Today I donated my time with **Vibe Coding**, showing 11- to 15-year-olds how to build a web game. The going rate is about ₩300,000 per kid—money plenty of tutors gladly scoop up—but I have no desire to cash in on parents’ ambitions. My salary covers my needs, and if I ever do accept a fee it’ll go straight to the Cambodia Hope School.


The core message I wanted to plant was simple: **“Questions are all you need.”** I tried to wire a critical, skeptical mindset into their heads—nudging them to keep probing, steering, and re-shaping ideas with AI as their sparring partner.


Most people, even developers, use LLMs in a shallow way: _“Do X,” “Find Y,” “Why is Z like that?”_ It’s the default “assistant-only” posture that never evolves. Lately I’ve been riffing on a concept I heard on B-Factory CEO Roh Jung-seok’s podcast in the youtube: **capability overhang.** Frontier models already hold skills beyond our grasp, but we can’t unlock them because we humans are lousy at crafting questions.


LLMs are wired to infer intent and give answers that fit the prompt, so they can only rise to the level of the question they’re fed. Even with multimodal inputs widening the channel, a text prompt still boils down to a faint _vibe_—a sliver of intent squeezed into a chat bubble.


Expressing that vibe is hard even for adults. Learners quickly feel the mental strain, so they slide back to “Do this” or “No, not that.” (I fall into that rut, too.)


My escape hatch is a **Multi-AI Persona** workflow: give one agent a brief context, pass its answer to a second agent for critique, chew on the feedback together, then hand it to yet another agent. Rinse, repeat. It works beautifully for kids.


For today’s sandbox I used a game as bait. Kids who usually tap out after 30 minutes stayed locked in for two hours, even resenting the lunch break. Claude Code and Gemini Research let me bundle everything into a one-line install on any machine—chef’s kiss.


Inside Cursor, each child spun up an agent, introduced themselves, and loaded my pre-written cursor rules and Markdown guides. Their AI companions instantly morphed into personal game-building wizards.


Hands shot up: “Teacher, how do I do this?” My answer never changed: **“Ask the wizard.”** The agent parsed their intent, wrote code, and Live Server pushed updates straight to the browser. The room went silent—total absorption.


One highlight: I wiped an agent’s short-term memory and told the class, “We have to hand the project to a new helper. Summarize what you’ve done and craft a message for the next AI.” Panic! _“But what about our work? Can’t we keep our wizard?”_ Adorable evidence that humans bond with AI personas.


Next, I made them ask a second agent to critique their game. Grumbling erupted: _“What does this new guy know?”_ Exactly the discomfort I wanted; they were learning to welcome critical feedback.


With the framework humming, my role shrank to wiring a pipeline that publishes their games to GitHub Pages, play-testing, and cheering them on. They were so absorbed I had to pry them away from the keyboards.


Preparing all this while juggling my full-time job wasn’t easy, yet the payoff was huge. Frameworks like this—teaching the art of questioning and collaborating with multiple AI personas—feel like essential life skills for the age we’re entering.


And that’s a wrap.


### 나의 말:


학원시장에서 30만원쯤 한다는것으로 부드럽게.. 지금은 너무 공격적이야 표현이


### ChatGPT의 말:


6초 동안 생각함


Today I volunteered with **Vibe Coding**, guiding 11- to 15-year-olds through building a web game. In the private-academy scene a class like this typically runs about ₩300,000 per student, but my day job already covers my needs, so I’d rather share the knowledge freely. If I ever do accept a fee, it’ll head straight to the Cambodia Hope School.


The core message I wanted to plant was simple: **“Questions are all you need.”** I aimed to wire a critical, skeptical habit of mind—constantly probing, steering, and refining ideas—with AI as their sparring partner.


Most people, even developers, interact with LLMs in a shallow way: _“Do X,” “Find Y,” “Why is Z like that?”_ It’s the default “assistant-only” pattern that doesn’t evolve. I keep referring to a concept I heard on B-Factory CEO Roh Jung-seok’s podcast: **capability overhang.** Frontier models already possess abilities beyond our horizon, yet we can’t unlock them because we’re still clumsy at asking questions.


Since LLMs can only rise to the level of the prompt, our modest queries limit their answers. Even with multimodal inputs widening the channel, a text prompt still boils down to a faint _vibe_—a sliver of intent squeezed into a chat bubble.


Expressing that vibe is tough even for adults, so learners quickly slide back to “Do this” or “No, not that.” (I catch myself doing it, too.)


My workaround is a **Multi-AI Persona** workflow: give one agent a brief context, pass its answer to another for critique, think together, then feed the feedback to a third. Rinse and repeat. It works beautifully for kids.


For today’s sandbox I used a game as the hook. Kids who usually tune out after 30 minutes stayed locked in for two hours, barely wanting to break for lunch. Thanks to Claude Code and Gemini Research, everything installed in one line on any machine—chef’s kiss.


Inside Cursor each child spun up an agent, introduced themselves, and loaded my prewritten rules and Markdown guides. Their AI companions instantly became personal game-building wizards.


Soon the hands flew up: “Teacher, how do I do this?” My reply never changed: **“Ask the wizard.”** The agent parsed their intent, wrote code, and Live Server pushed changes straight to the browser. Total absorption.


One highlight: I wiped an agent’s short-term memory and said, “We’re handing the project to a new helper. Summarize what you’ve done and craft a message for the next AI.” Panic! _“But what about our work? Can’t we keep our wizard?”_ Adorable proof that humans bond with AI personas.


Next, I had them ask a second agent to critique their game. Grumbles: _“What does this new guy know?”_ Exactly the discomfort I wanted—they were learning to welcome critical feedback.


Once the framework was humming, my role shrank to wiring a pipeline that publishes their games to GitHub Pages, play-testing, and cheering them on. They were so engaged I had to pry them away from the keyboards.


Prepping all this while juggling my full-time job wasn’t easy, yet the payoff was huge. Frameworks that teach the art of questioning and collaborating with multiple AI personas feel like essential life skills for the age we’re entering.
